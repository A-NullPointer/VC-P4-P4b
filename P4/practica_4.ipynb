{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baf059b7",
   "metadata": {},
   "source": [
    "# Práctica 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27789301",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a0ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import logging\n",
    "import warnings\n",
    "import signal\n",
    "import sys\n",
    "import csv\n",
    "import cv2\n",
    "import pytesseract\n",
    "import easyocr\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "\n",
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Evitar crash OpenMP en Windows\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "# Forzar GPU si está disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ca1be",
   "metadata": {},
   "source": [
    "### Verificación de uso de gpu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a309a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c7960",
   "metadata": {},
   "source": [
    "## Entrenamineto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827abb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el modelo preentrenado\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "model.train(\n",
    "    data=r\"C:\\Users\\asmae\\Documents\\INGENIERIA INFORMATICA\\4 CUARTO\\VC\\Practicas\\VC_P4&P5\\dataset\\data.yaml\",\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name=\"license_plate_augmented\",\n",
    "    workers=2,       # para Windows/Jupyter\n",
    "    plots=False,\n",
    "    patience=10,     # early stopping\n",
    "    augment=True,    # activa augmentations\n",
    "    mosaic=1,        # combina varias imágenes\n",
    "    mixup=0.5,       # mezcla imágenes 50%\n",
    "    copy_paste=0.3,  # copia/pega objetos en otras imágenes\n",
    "    auto_augment=\"randaugment\"  # auto augment avanzado\n",
    ")\n",
    "\n",
    "metrics = model.val()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac02da",
   "metadata": {},
   "source": [
    "## Detección en el vídeo:\n",
    "### Conteo con Tessercat e EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c46da",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_CLASSES = {\n",
    "    0: \"persona\",\n",
    "    2: \"coche\",\n",
    "    3: \"motocicleta\",\n",
    "    5: \"autobus\",\n",
    "    7: \"camion\"\n",
    "}\n",
    "\n",
    "base_mnodel = YOLO(\"yolo11n.pt\")  \n",
    "lp_model = YOLO(r\"runs/detect/license_plate_augmented/weights/best.pt\")\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "video_path = \"C0142.MP4\"\n",
    "output_path_tesseract = \"salida_detecciones_pytesseract.mp4\"\n",
    "output_path_easyocr = \"salida_detecciones_easyocr.mp4\"\n",
    "csv_path_tesseract = \"detecciones_pytesseract.csv\"\n",
    "csv_path_easyocr = \"detecciones_easyocr.csv\"\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "if not video.isOpened():\n",
    "    print(\"Error al abrir el video\")\n",
    "    exit()\n",
    "\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_tesseract = cv2.VideoWriter(output_path_tesseract, fourcc, fps, (width, height))\n",
    "out_easyocr = cv2.VideoWriter(output_path_easyocr, fourcc, fps, (width, height))\n",
    "\n",
    "def cerrar_recursos(signal_received=None, frame=None):\n",
    "    print(\"\\nGuardando y cerrando correctamente...\")\n",
    "    video.release()\n",
    "    out_tesseract.release()\n",
    "    out_easyocr.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, cerrar_recursos)\n",
    "signal.signal(signal.SIGTERM, cerrar_recursos)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def draw_text_with_background(img, text, pos, font_scale=0.6, thickness=2, text_color=(255, 255, 255), bg_color=(0, 0, 0)):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    x, y = pos\n",
    "    y = min(y, img.shape[0] - text_height - 10)\n",
    "    x = max(0, min(x, img.shape[1] - text_width - 10))\n",
    "    cv2.rectangle(img, (x - 5, y - text_height - 5), (x + text_width + 5, y + baseline + 5), bg_color, -1)\n",
    "    cv2.putText(img, text, (x, y), font, font_scale, text_color, thickness)\n",
    "    return text_height + baseline + 10\n",
    "\n",
    "def leer_matricula_easyocr(imagen):\n",
    "    resultado = reader.readtext(imagen, detail=0, paragraph=False)\n",
    "    textos = [''.join(c for c in t if c.isalnum()) for t in resultado if len(t) > 2]\n",
    "    return ' '.join(textos) if textos else \"\"\n",
    "\n",
    "object_tracks = {}\n",
    "exit_counts = defaultdict(lambda: {\"izquierda\": 0, \"derecha\": 0, \"arriba\": 0, \"abajo\": 0})\n",
    "unique_ids = defaultdict(set)\n",
    "\n",
    "try:\n",
    "    with open(csv_path_tesseract, mode='w', newline='') as f_tesseract, open(csv_path_easyocr, mode='w', newline='') as f_easyocr:\n",
    "        writer_tesseract = csv.writer(f_tesseract)\n",
    "        writer_tesseract.writerow([\"fotograma\", \"tipo_objeto\", \"confianza\", \"identificador_tracking\", \"x1\", \"y1\", \"x2\", \"y2\", \"matricula_en_su_caso\", \"confianza_matricula\", \"mx1\", \"my1\", \"mx2\", \"my2\", \"texto_matricula\"])\n",
    "        \n",
    "        writer_easyocr = csv.writer(f_easyocr)\n",
    "        writer_easyocr.writerow([\"fotograma\", \"tipo_objeto\", \"confianza\", \"identificador_tracking\", \"x1\", \"y1\", \"x2\", \"y2\", \"matricula_en_su_caso\", \"confianza_matricula\", \"mx1\", \"my1\", \"mx2\", \"my2\", \"texto_matricula\"])\n",
    "\n",
    "        frame_num = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_num += 1\n",
    "            print(f\"Frame num: {frame_num}\")\n",
    "            \n",
    "            display_frame_tesseract = frame.copy()\n",
    "            display_frame_easyocr = frame.copy()\n",
    "\n",
    "            results_coco = base_mnodel.track(frame, classes=[0, 2, 3, 5, 7], persist=True, tracker=\"bytetrack.yaml\", verbose=False)\n",
    "\n",
    "            display_frame_tesseract = results_coco[0].plot()\n",
    "            display_frame_easyocr = display_frame_tesseract.copy()\n",
    "\n",
    "            for box in results_coco[0].boxes:\n",
    "                cls_id = int(box.cls[0].item())\n",
    "                conf = box.conf[0].item()\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                class_model = VEHICLE_CLASSES.get(cls_id, \"desconocido\")\n",
    "                track_id = int(box.id[0]) if box.id is not None else None\n",
    "\n",
    "                if track_id is not None:\n",
    "                    unique_ids[class_model].add(track_id)\n",
    "                    cx = int((x1 + x2) / 2)\n",
    "                    cy = int((y1 + y2) / 2)\n",
    "                    if track_id not in object_tracks:\n",
    "                        object_tracks[track_id] = {\"centros\": [], \"tipo\": class_model, \"salido\": False}\n",
    "                    object_tracks[track_id][\"centros\"].append((cx, cy))\n",
    "                    if not object_tracks[track_id][\"salido\"]:\n",
    "                        if cx <= 5:\n",
    "                            exit_counts[class_model][\"izquierda\"] += 1\n",
    "                            object_tracks[track_id][\"salido\"] = True\n",
    "                        elif cx >= width - 5:\n",
    "                            exit_counts[class_model][\"derecha\"] += 1\n",
    "                            object_tracks[track_id][\"salido\"] = True\n",
    "                        elif cy <= 5:\n",
    "                            exit_counts[class_model][\"arriba\"] += 1\n",
    "                            object_tracks[track_id][\"salido\"] = True\n",
    "                        elif cy >= height - 5:\n",
    "                            exit_counts[class_model][\"abajo\"] += 1\n",
    "                            object_tracks[track_id][\"salido\"] = True\n",
    "\n",
    "                plate_detected = False\n",
    "                conf_plate = None\n",
    "                mx1 = my1 = mx2 = my2 = None\n",
    "                plate_text_tesseract = \"\"\n",
    "                plate_text_easyocr = \"\"\n",
    "\n",
    "                if class_model != \"persona\":\n",
    "                    vehicle_roi = frame[y1:y2, x1:x2]\n",
    "                    results_plate = lp_model.predict(vehicle_roi, save=False, show=False, verbose=False)\n",
    "\n",
    "                    if len(results_plate[0].boxes) > 0:\n",
    "                        plate_detected = True\n",
    "                        plate_plot = results_plate[0].plot()\n",
    "                        display_frame_tesseract[y1:y2, x1:x2] = plate_plot\n",
    "                        display_frame_easyocr[y1:y2, x1:x2] = plate_plot\n",
    "                        \n",
    "                        plate_box = results_plate[0].boxes[0]\n",
    "                        px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                        conf_plate = plate_box.conf[0].item()\n",
    "                        mx1, my1, mx2, my2 = x1 + px1, y1 + py1, x1 + px2, y1 + py2\n",
    "                        \n",
    "                        plate_roi = vehicle_roi[py1:py2, px1:px2]\n",
    "                        \n",
    "                        if plate_roi.size > 0:\n",
    "                            plate_roi_rgb = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2RGB)\n",
    "                            plate_text_tesseract = pytesseract.image_to_string(plate_roi_rgb).replace(\"\\n\", \" \").strip()\n",
    "                            try:\n",
    "                                plate_text_easyocr = leer_matricula_easyocr(plate_roi_rgb)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error EasyOCR frame {frame_num}: {e}\")\n",
    "                                plate_text_easyocr = \"\"\n",
    "\n",
    "                    info_y = y2 + 10\n",
    "                    \n",
    "                    if plate_detected:\n",
    "                        status_text = f\"Matricula: SI (Conf: {conf_plate:.2f})\"\n",
    "                        offset_t = draw_text_with_background(display_frame_tesseract, status_text, (x1, info_y), 0.5, 2, (0, 255, 0), (0, 0, 0))\n",
    "                        offset_e = draw_text_with_background(display_frame_easyocr, status_text, (x1, info_y), 0.5, 2, (0, 255, 0), (0, 0, 0))\n",
    "                        \n",
    "                        if plate_text_tesseract:\n",
    "                            draw_text_with_background(display_frame_tesseract, f\"Texto: {plate_text_tesseract}\", (x1, info_y + offset_t), 0.6, 2, (255, 255, 0), (0, 0, 0))\n",
    "                        else:\n",
    "                            draw_text_with_background(display_frame_tesseract, \"Texto: No legible\", (x1, info_y + offset_t), 0.5, 2, (0, 165, 255), (0, 0, 0))\n",
    "                        \n",
    "                        if plate_text_easyocr:\n",
    "                            draw_text_with_background(display_frame_easyocr, f\"Texto: {plate_text_easyocr}\", (x1, info_y + offset_e), 0.6, 2, (255, 255, 0), (0, 0, 0))\n",
    "                        else:\n",
    "                            draw_text_with_background(display_frame_easyocr, \"Texto: No legible\", (x1, info_y + offset_e), 0.5, 2, (0, 165, 255), (0, 0, 0))\n",
    "                    else:\n",
    "                        draw_text_with_background(display_frame_tesseract, \"Matricula: NO\", (x1, info_y), 0.5, 2, (0, 0, 255), (0, 0, 0))\n",
    "                        draw_text_with_background(display_frame_easyocr, \"Matricula: NO\", (x1, info_y), 0.5, 2, (0, 0, 255), (0, 0, 0))\n",
    "\n",
    "                writer_tesseract.writerow([frame_num, class_model, conf, track_id, x1, y1, x2, y2, plate_detected, conf_plate, mx1, my1, mx2, my2, plate_text_tesseract])\n",
    "                writer_easyocr.writerow([frame_num, class_model, conf, track_id, x1, y1, x2, y2, plate_detected, conf_plate, mx1, my1, mx2, my2, plate_text_easyocr])\n",
    "\n",
    "            overlay_t = display_frame_tesseract.copy()\n",
    "            panel_x, panel_y = 10, 30\n",
    "            draw_text_with_background(overlay_t, f\"Frame: {frame_num}\", (panel_x, panel_y), 0.6, 2, (255, 255, 255), (0, 0, 0))\n",
    "            panel_y += 30\n",
    "            for tipo in VEHICLE_CLASSES.values():\n",
    "                draw_text_with_background(overlay_t, f\"{tipo.capitalize()}: {len(unique_ids[tipo])}\", (panel_x, panel_y), 0.6, 2, (0, 255, 255), (0, 0, 0))\n",
    "                panel_y += 25\n",
    "            panel_y += 10\n",
    "            for tipo, direcciones in exit_counts.items():\n",
    "                draw_text_with_background(overlay_t, f\"{tipo.upper()}:\", (panel_x, panel_y), 0.6, 2, (255, 255, 255), (50, 50, 50))\n",
    "                panel_y += 22\n",
    "                for dir, count in direcciones.items():\n",
    "                    draw_text_with_background(overlay_t, f\"  {dir}: {count}\", (panel_x + 20, panel_y), 0.55, 2, (0, 200, 0), (0, 0, 0))\n",
    "                    panel_y += 20\n",
    "                panel_y += 10\n",
    "            cv2.addWeighted(overlay_t, 0.9, display_frame_tesseract, 0.1, 0, display_frame_tesseract)\n",
    "\n",
    "            overlay_e = display_frame_easyocr.copy()\n",
    "            panel_x, panel_y = 10, 30\n",
    "            draw_text_with_background(overlay_e, f\"Frame: {frame_num}\", (panel_x, panel_y), 0.6, 2, (255, 255, 255), (0, 0, 0))\n",
    "            panel_y += 30\n",
    "            for tipo in VEHICLE_CLASSES.values():\n",
    "                draw_text_with_background(overlay_e, f\"{tipo.capitalize()}: {len(unique_ids[tipo])}\", (panel_x, panel_y), 0.6, 2, (0, 255, 255), (0, 0, 0))\n",
    "                panel_y += 25\n",
    "            panel_y += 10\n",
    "            for tipo, direcciones in exit_counts.items():\n",
    "                draw_text_with_background(overlay_e, f\"{tipo.upper()}:\", (panel_x, panel_y), 0.6, 2, (255, 255, 255), (50, 50, 50))\n",
    "                panel_y += 22\n",
    "                for dir, count in direcciones.items():\n",
    "                    draw_text_with_background(overlay_e, f\"  {dir}: {count}\", (panel_x + 20, panel_y), 0.55, 2, (0, 200, 0), (0, 0, 0))\n",
    "                    panel_y += 20\n",
    "                panel_y += 10\n",
    "            cv2.addWeighted(overlay_e, 0.9, display_frame_easyocr, 0.1, 0, display_frame_easyocr)\n",
    "\n",
    "            out_tesseract.write(display_frame_tesseract)\n",
    "            out_easyocr.write(display_frame_easyocr)\n",
    "finally:\n",
    "    video.release()\n",
    "    out_tesseract.release()\n",
    "    out_easyocr.release()\n",
    "    print(f\"Video Tesseract: {output_path_tesseract}\")\n",
    "    print(f\"Video EasyOCR: {output_path_easyocr}\")\n",
    "    print(f\"CSV Tesseract: {csv_path_tesseract}\")\n",
    "    print(f\"CSV EasyOCR: {csv_path_easyocr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f1f47",
   "metadata": {},
   "source": [
    "### Conteo con SmolVLM\n",
    "\n",
    "### Carga del modelo SmolVLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "\n",
    "print(\"Cargando SmolVLM...\")\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(\"SmolVLM cargado!\")\n",
    "\n",
    "def leer_matricula(imagen):\n",
    "    \"\"\"\n",
    "    imagen: puede ser ruta (str), PIL Image, o numpy array (frame de OpenCV)\n",
    "    \"\"\"\n",
    "    if isinstance(imagen, str):\n",
    "        img = Image.open(imagen).convert(\"RGB\")\n",
    "    elif isinstance(imagen, np.ndarray):\n",
    "        if len(imagen.shape) == 3 and imagen.shape[2] == 3:\n",
    "            img = Image.fromarray(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            img = Image.fromarray(imagen)\n",
    "    else:\n",
    "        img = imagen.convert(\"RGB\")\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"What is the license plate number in this image? Only respond with the alphanumeric characters, without spaces or special characters.\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    \n",
    "    inputs = processor(\n",
    "        text=prompt,\n",
    "        images=[img],\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    resultado = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    if \"Assistant:\" in resultado:\n",
    "        resultado = resultado.split(\"Assistant:\")[-1].strip()\n",
    "    elif \"\\n\" in resultado:\n",
    "        resultado = resultado.split(\"\\n\")[-1].strip()\n",
    "    \n",
    "    return resultado.replace(\"/s\", \"\").replace(\"-\", \"\").replace(\"_\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f98a1",
   "metadata": {},
   "source": [
    "### Generación del vídeo con SmolVLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_CLASSES = {\n",
    "    0: \"persona\",\n",
    "    2: \"coche\",\n",
    "    3: \"motocicleta\",\n",
    "    5: \"autobus\",\n",
    "    7: \"camion\"\n",
    "}\n",
    "\n",
    "base_mnodel = YOLO(\"yolo11n.pt\")  \n",
    "lp_model = YOLO(r\"runs/detect/license_plate_augmented/weights/best.pt\")\n",
    "\n",
    "video_path = \"C0142.MP4\"\n",
    "output_path = \"salida_detecciones_smolvlm.mp4\"\n",
    "csv_path = \"detecciones_smolvlm.csv\"\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "if not video.isOpened():\n",
    "    print(\"Error al abrir el video\")\n",
    "    exit()\n",
    "\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "def cerrar_recursos(signal_received=None, frame=None):\n",
    "    print(\"\\nGuardando y cerrando correctamente...\")\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, cerrar_recursos)\n",
    "signal.signal(signal.SIGTERM, cerrar_recursos)\n",
    "\n",
    "def draw_text_with_background(img, text, pos, font_scale=0.6, thickness=2, text_color=(255, 255, 255), bg_color=(0, 0, 0)):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    x, y = pos\n",
    "    y = min(y, img.shape[0] - text_height - 10)\n",
    "    x = max(0, min(x, img.shape[1] - text_width - 10))\n",
    "    cv2.rectangle(img, (x - 5, y - text_height - 5), (x + text_width + 5, y + baseline + 5), bg_color, -1)\n",
    "    cv2.putText(img, text, (x, y), font, font_scale, text_color, thickness)\n",
    "    return text_height + baseline + 10\n",
    "\n",
    "try:\n",
    "    with open(csv_path, mode='w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"fotograma\", \"tipo_objeto\", \"confianza\", \"identificador_tracking\", \"x1\", \"y1\", \"x2\", \"y2\", \"matricula_en_su_caso\", \"confianza_matricula\", \"mx1\", \"my1\", \"mx2\", \"my2\", \"texto_matricula\"])\n",
    "\n",
    "        frame_num = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_num += 1\n",
    "            print(f\"Frame num: {frame_num}\")\n",
    "            \n",
    "            display_frame = frame.copy()\n",
    "            results_coco = base_mnodel.track(frame, classes=[0, 2, 3, 5, 7], persist=True, tracker=\"bytetrack.yaml\", verbose=False)\n",
    "            display_frame = results_coco[0].plot()\n",
    "\n",
    "            for box in results_coco[0].boxes:\n",
    "                cls_id = int(box.cls[0].item())\n",
    "                conf = box.conf[0].item()\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                class_model = VEHICLE_CLASSES.get(cls_id, \"desconocido\")\n",
    "                track_id = int(box.id[0]) if box.id is not None else None\n",
    "\n",
    "                plate_detected = False\n",
    "                conf_plate = None\n",
    "                mx1 = my1 = mx2 = my2 = None\n",
    "                plate_text = \"\"\n",
    "\n",
    "                if class_model != \"persona\":\n",
    "                    vehicle_roi = frame[y1:y2, x1:x2]\n",
    "                    results_plate = lp_model.predict(vehicle_roi, save=False, show=False, verbose=False)\n",
    "\n",
    "                    if len(results_plate[0].boxes) > 0:\n",
    "                        plate_detected = True\n",
    "                        plate_plot = results_plate[0].plot()\n",
    "                        display_frame[y1:y2, x1:x2] = plate_plot\n",
    "                        \n",
    "                        plate_box = results_plate[0].boxes[0]\n",
    "                        px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                        conf_plate = plate_box.conf[0].item()\n",
    "                        mx1, my1, mx2, my2 = x1 + px1, y1 + py1, x1 + px2, y1 + py2\n",
    "                        \n",
    "                        plate_roi = vehicle_roi[py1:py2, px1:px2]\n",
    "                        \n",
    "                        if plate_roi.size > 0:\n",
    "                            plate_roi_rgb = cv2.cvtColor(plate_roi, cv2.COLOR_BGR2RGB)\n",
    "                            try:\n",
    "                                plate_text = leer_matricula(plate_roi_rgb)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error SmolVLM frame {frame_num}: {e}\")\n",
    "                                plate_text = \"\"\n",
    "\n",
    "                    info_y = y2 + 10\n",
    "                    \n",
    "                    if plate_detected:\n",
    "                        status_text = f\"Matricula: SI (Conf: {conf_plate:.2f})\"\n",
    "                        offset = draw_text_with_background(display_frame, status_text, (x1, info_y), 0.5, 2, (0, 255, 0), (0, 0, 0))\n",
    "                        \n",
    "                        if plate_text:\n",
    "                            draw_text_with_background(display_frame, f\"Texto: {plate_text}\", (x1, info_y + offset), 0.6, 2, (255, 255, 0), (0, 0, 0))\n",
    "                        else:\n",
    "                            draw_text_with_background(display_frame, \"Texto: No legible\", (x1, info_y + offset), 0.5, 2, (0, 165, 255), (0, 0, 0))\n",
    "                    else:\n",
    "                        draw_text_with_background(display_frame, \"Matricula: NO\", (x1, info_y), 0.5, 2, (0, 0, 255), (0, 0, 0))\n",
    "\n",
    "                writer.writerow([frame_num, class_model, conf, track_id, x1, y1, x2, y2, plate_detected, conf_plate, mx1, my1, mx2, my2, plate_text])\n",
    "            \n",
    "            out.write(display_frame)\n",
    "finally:\n",
    "    print(\"\\nFinalizando ejecución, guardando video y CSV...\")\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Video guardado en: {output_path}\")\n",
    "    print(f\"CSV guardado en: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3adbb3",
   "metadata": {},
   "source": [
    "## Conteo de clases a partir de los csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a879bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados para detecciones_pytesseract.csv:\n",
      "  autobus: 9 únicos\n",
      "  coche: 261 únicos\n",
      "  camion: 11 únicos\n",
      "  persona: 48 únicos\n",
      "  motocicleta: 7 únicos\n",
      "\n",
      "Resultados para detecciones_easyocr.csv:\n",
      "  autobus: 9 únicos\n",
      "  coche: 261 únicos\n",
      "  camion: 11 únicos\n",
      "  persona: 48 únicos\n",
      "  motocicleta: 7 únicos\n",
      "\n",
      "Resultados para detecciones_smolvlm.csv:\n",
      "  autobus: 7 únicos\n",
      "  coche: 98 únicos\n",
      "  camion: 8 únicos\n",
      "  persona: 21 únicos\n",
      "  motocicleta: 2 únicos\n"
     ]
    }
   ],
   "source": [
    "def count_classes(csv_file):\n",
    "    objetos = {}\n",
    "\n",
    "    with open(csv_file, newline='', encoding='latin-1') as csvfile:\n",
    "        lector = csv.DictReader(csvfile)\n",
    "        for fila in lector:\n",
    "            tipo = fila['tipo_objeto']\n",
    "            track_id = fila['identificador_tracking']\n",
    "\n",
    "            if track_id and track_id.lower() != \"none\":\n",
    "                if tipo not in objetos:\n",
    "                    objetos[tipo] = set()\n",
    "                objetos[tipo].add(track_id)\n",
    "\n",
    "    print(f\"\\nResultados para {csv_file}:\")\n",
    "    for tipo, ids in objetos.items():\n",
    "        print(f\"  {tipo}: {len(ids)} únicos\")\n",
    "\n",
    "count_classes(\"detecciones_pytesseract.csv\")\n",
    "count_classes(\"detecciones_easyocr.csv\")\n",
    "count_classes(\"detecciones_smolvlm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f274935",
   "metadata": {},
   "source": [
    "## Determinación del flujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56587a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "VEHICLE_CLASSES = {0:\"persona\",2:\"coche\",3:\"motocicleta\",5:\"autobus\",7:\"camion\"}\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "video_path = \"C0142.MP4\"\n",
    "output_path = \"salida_flujo_direccional.mp4\"\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "if not video.isOpened():\n",
    "    print(\"Error al abrir el video\"); exit()\n",
    "\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "def cerrar(signal_received=None, frame=None):\n",
    "    print(\"\\nCerrando...\"); video.release(); out.release(); sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, cerrar)\n",
    "signal.signal(signal.SIGTERM, cerrar)\n",
    "\n",
    "def draw_text(img, text, pos, color=(255,255,255), bg=(0,0,0)):\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    (tw,th),_=cv2.getTextSize(text,font,0.6,2)\n",
    "    x,y=pos; cv2.rectangle(img,(x-5,y-th-5),(x+tw+5,y+5),bg,-1)\n",
    "    cv2.putText(img,text,(x,y),font,0.6,color,2)\n",
    "\n",
    "tracks = {}  # id -> {\"tipo\":, \"positions\":deque, \"active\":True}\n",
    "entry_counts = defaultdict(lambda:{\"izquierda\":0,\"derecha\":0,\"arriba\":0,\"abajo\":0})\n",
    "exit_counts  = defaultdict(lambda:{\"izquierda\":0,\"derecha\":0,\"arriba\":0,\"abajo\":0})\n",
    "margin = 40\n",
    "min_frames_inside = 5\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret: break\n",
    "    frame_num += 1\n",
    "\n",
    "    results = model.track(frame, classes=list(VEHICLE_CLASSES.keys()), persist=True, tracker=\"bytetrack.yaml\", verbose=False)\n",
    "    display = results[0].plot()\n",
    "    current_ids = set()\n",
    "\n",
    "    for box in results[0].boxes:\n",
    "        cls_id = int(box.cls[0].item()); tipo = VEHICLE_CLASSES.get(cls_id,\"desconocido\")\n",
    "        track_id = int(box.id[0]) if box.id is not None else None\n",
    "        if track_id is None: continue\n",
    "        x1,y1,x2,y2 = map(int, box.xyxy[0])\n",
    "        cx,cy = int((x1+x2)/2),int((y1+y2)/2)\n",
    "        current_ids.add(track_id)\n",
    "\n",
    "        if track_id not in tracks:\n",
    "            tracks[track_id] = {\"tipo\":tipo, \"positions\":deque(maxlen=10), \"entered\":False}\n",
    "        tracks[track_id][\"positions\"].append((cx,cy))\n",
    "\n",
    "        # Detectar si entra desde un borde\n",
    "        if not tracks[track_id][\"entered\"]:\n",
    "            if len(tracks[track_id][\"positions\"])>=min_frames_inside:\n",
    "                first_x,first_y = tracks[track_id][\"positions\"][0]\n",
    "                if first_x < margin: entry_counts[tipo][\"izquierda\"]+=1\n",
    "                elif first_x > width-margin: entry_counts[tipo][\"derecha\"]+=1\n",
    "                elif first_y < margin: entry_counts[tipo][\"arriba\"]+=1\n",
    "                elif first_y > height-margin: entry_counts[tipo][\"abajo\"]+=1\n",
    "                tracks[track_id][\"entered\"]=True\n",
    "\n",
    "    # Detectar salidas\n",
    "    for tid,data in list(tracks.items()):\n",
    "        if tid not in current_ids and len(data[\"positions\"])>0:\n",
    "            cx,cy = data[\"positions\"][-1]\n",
    "            tipo=data[\"tipo\"]\n",
    "            if cx < margin: exit_counts[tipo][\"izquierda\"]+=1\n",
    "            elif cx > width-margin: exit_counts[tipo][\"derecha\"]+=1\n",
    "            elif cy < margin: exit_counts[tipo][\"arriba\"]+=1\n",
    "            elif cy > height-margin: exit_counts[tipo][\"abajo\"]+=1\n",
    "            del tracks[tid]\n",
    "\n",
    "    # Dibujar bordes y estadísticas\n",
    "    cv2.rectangle(display,(0,0),(margin,height),(0,0,255),2)\n",
    "    cv2.rectangle(display,(width-margin,0),(width,height),(0,0,255),2)\n",
    "    cv2.rectangle(display,(0,0),(width,margin),(0,0,255),2)\n",
    "    cv2.rectangle(display,(0,height-margin),(width,height),(0,0,255),2)\n",
    "\n",
    "    y=30\n",
    "    draw_text(display,f\"Frame {frame_num}\",(10,y)); y+=30\n",
    "    draw_text(display,\"== ENTRADAS ==\",(10,y),(0,255,0)); y+=25\n",
    "    for t,dirs in entry_counts.items():\n",
    "        draw_text(display,f\"{t}: izq {dirs['izquierda']} der {dirs['derecha']} arr {dirs['arriba']} aba {dirs['abajo']}\",(10,y),(0,255,0))\n",
    "        y+=25\n",
    "    y+=10\n",
    "    draw_text(display,\"== SALIDAS ==\",(10,y),(0,200,255)); y+=25\n",
    "    for t,dirs in exit_counts.items():\n",
    "        draw_text(display,f\"{t}: izq {dirs['izquierda']} der {dirs['derecha']} arr {dirs['arriba']} aba {dirs['abajo']}\",(10,y),(0,200,255))\n",
    "        y+=25\n",
    "\n",
    "    out.write(display)\n",
    "\n",
    "video.release(); out.release()\n",
    "print(\"Vídeo con flujo direccional guardado:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246de4e",
   "metadata": {},
   "source": [
    "## Anonimación de objetos detectados en el vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01030e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def anonimize(frame, *box):\n",
    "    x1, y1,x2, y2 = box\n",
    "    frame_copy = frame[y1:y2, x1:x2].copy()\n",
    "    return cv2.GaussianBlur(frame_copy, (51,51), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c67f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_mnodel = YOLO(\"yolo11n.pt\")  \n",
    "lp_model = YOLO(r\"runs/detect/license_plate_augmented/weights/best.pt\")\n",
    "\n",
    "video_path = \"C0142.MP4\"\n",
    "output_path = \"salida_anonimación_de_personas_y_matriculas.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error al abrir el video\")\n",
    "    exit()\n",
    "\n",
    "# Extraer propiedades del video original para replicarlas en la salida\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))           # Fotogramas por segundo\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Ancho\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) # Alto\n",
    "\n",
    "# Codec de video: 'mp4v' es compatible con la mayoría de reproductores\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_num += 1\n",
    "    #display_frame = frame.copy()\n",
    "\n",
    "    results_coco = base_mnodel.track(\n",
    "        frame, \n",
    "        classes=[0, 2, 3, 5, 7], \n",
    "        persist=True, \n",
    "        tracker=\"bytetrack.yaml\"\n",
    "    )\n",
    "\n",
    "    for box in results_coco[0].boxes:\n",
    "        # ID de clase (0=person, 2=car)\n",
    "        cls_id = int(box.cls[0].item())\n",
    "        #conf = box.conf[0].item()\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        tipo = \"persona\" if cls_id == 0 else \"vehiculo\"\n",
    "        \n",
    "        if tipo == \"persona\":\n",
    "            if y2 > y1 and x2 > x1:\n",
    "                blurred_roi = anonimize(frame, x1, y1, x2, y2)\n",
    "                frame[y1:y2, x1:x2] = blurred_roi\n",
    "                #frame[y1:y2, x1:x2] = anonimize(frame, x1, y1, x2, y2)\n",
    "        \n",
    "        if tipo == \"vehiculo\":\n",
    "            car_roi = frame[y1:y2, x1:x2]\n",
    "            results_plate = lp_model.predict(car_roi, save=False, show=False)\n",
    "\n",
    "            # Si se detectó al menos una matrícula\n",
    "            if len(results_plate[0].boxes) > 0:\n",
    "                # Tomar la detección con mayor confianza (índice 0)\n",
    "                plate_box = results_plate[0].boxes[0]\n",
    "                px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                \n",
    "                mx1, my1, mx2, my2 = x1 + px1, y1 + py1, x1 + px2, y1 + py2\n",
    "                if my2>my1 and mx2>mx1:\n",
    "                    blurred_plate_roi = anonimize(frame, mx1, my1, mx2, my2)\n",
    "                    frame[my1:my2, mx1:mx2] = blurred_plate_roi\n",
    "\n",
    "    display_frame = frame.copy()\n",
    "\n",
    "    for box in results_coco[0].boxes:\n",
    "        cls_id = int(box.cls[0].item()) \n",
    "        conf = box.conf[0].item() # Confianza de la detección [0-1]\n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        tipo = \"persona\" if cls_id == 0 else \"vehiculo\"\n",
    "        \n",
    "        # Obtener ID de tracking (puede ser None si el objeto acaba de aparecer)\n",
    "        track_id = int(box.id[0]) if box.id is not None else None\n",
    "\n",
    "        color = (0, 255, 0) if tipo == \"vehiculo\" else (0, 0, 255)\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        label = f\"{tipo} ID:{track_id} {conf:.2f}\"\n",
    "        cv2.putText(display_frame, label, (x1, y1-10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "        if tipo == \"vehiculo\":\n",
    "            car_roi = frame[y1:y2, x1:x2]\n",
    "            results_plate = lp_model.predict(car_roi, save=False, show=False)\n",
    "\n",
    "            if len(results_plate[0].boxes) > 0:\n",
    "            # Inferencia del modelo custom SOLO en esta ROI\n",
    "                results_plate = lp_model.predict(car_roi, save=False, show=False)\n",
    "            \n",
    "            # Si se detectó al menos una matrícula\n",
    "            if len(results_plate[0].boxes) > 0:\n",
    "                # Tomar la detección con mayor confianza (índice 0)\n",
    "                plate_box = results_plate[0].boxes[0]\n",
    "                px1, py1, px2, py2 = map(int, plate_box.xyxy[0])\n",
    "                conf_plate = plate_box.conf[0].item()\n",
    "                \n",
    "                # CONVERSIÓN DE COORDENADAS: Relativas → Absolutas\n",
    "                # Las coordenadas (px1, py1, px2, py2) son relativas a car_roi\n",
    "                # Necesitamos convertirlas al sistema de coordenadas del frame completo\n",
    "                mx1, my1, mx2, my2 = x1 + px1, y1 + py1, x1 + px2, y1 + py2\n",
    "                \n",
    "                # Dibujar bounding box de la matrícula (azul)\n",
    "                cv2.rectangle(display_frame, (mx1, my1), (mx2, my2), (255, 0, 0), 2)\n",
    "                \n",
    "                plate_roi = car_roi[py1:py2, px1:px2]\n",
    "                \n",
    "    out.write(display_frame)\n",
    "\n",
    "    # Feedback de progreso cada 30 frames (~1 segundo a 30fps)\n",
    "    if frame_num % 30 == 0:\n",
    "        print(f\"Procesando frame {frame_num}...\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Video procesado guardado en: {output_path}\")\n",
    "print(f\"Total de frames procesados: {frame_num}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
